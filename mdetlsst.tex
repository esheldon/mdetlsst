% mnras
% \documentclass[fleqn,useAMS,usenatbib]{mnras}

% apj
%\documentclass[iop, twocolappendix, appendixfloats, numberedappendix, apj]{emulateapj}
\documentclass[iop, twocolappendix, appendixfloats, numberedappendix, apj]{hackemulateapj}
%\documentclass{emulateapj}

%=====================================================================
% CUSTOM: PACKAGES, MACROS & SETTINGS
%=====================================================================
% packages for figures
\usepackage{graphicx,todonotes}

% packages for symbols
\usepackage{latexsym,amssymb}

% AMS-LaTeX package for e.g. subequations
\usepackage{amsmath,morefloats}
\usepackage[backref,breaklinks,colorlinks,citecolor=blue]{hyperref}
\usepackage{natbib,graphicx,amsmath,subfigure,color,xcolor}
%\usepackage{natbib,graphicx,amsmath,subfigure,color,xcolor,hyperref}
\usepackage{verbatim}
\usepackage{threeparttable}

\usepackage{pgfplots}
\pgfplotsset{compat=newest}
\usepgfplotslibrary{fillbetween}
\usepgfplotslibrary{groupplots}


%\usepackage{lineno}
%\linenumbers

\topmargin-1cm

\newcommand\notedo[1]{\todo[color=yellow, inline, size=\small]{To do:#1}}
\newcommand\notewrite[1]{\todo[color=orange, inline, size=\small]{To write: #1}}
\newcommand\noteask[1]{\todo[color=cyan, inline, size=\small]{To ask: #1}}
\newcommand\notecontrib[1]{\todo[color=green, inline, size=\small]{Contributors: #1}}
\newcommand{\mrbtodo}[1]{\textcolor{red}{[MRB TODO: \bf #1]}}
\newcommand{\esstodo}[1]{\textcolor{orange}{[ESS TODO: \bf #1]}}
\newcommand{\ess}[1]{\textcolor{blue}{[ESS: \bf #1]}}
\newcommand{\mrb}[1]{\textcolor{purple}{[MRB: \bf #1]}}

\newcommand{\descwl}{\texttt{WeakLensingDeblending}}

\newcommand{\vecg}{\mbox{\boldmath $g$}}
\newcommand{\vece}{\mbox{\boldmath $e$}}
\newcommand{\veck}{\mbox{\boldmath $k$}}
\newcommand{\vecQ}{\mbox{\boldmath $Q$}}
\newcommand{\vecF}{\mbox{\boldmath $F$}}
\newcommand{\vecD}{\mbox{\boldmath $D$}}
\newcommand{\vecc}{\mbox{\boldmath $c$}}
\newcommand{\vecm}{\mbox{\boldmath $m$}}
\newcommand{\matR}{\mbox{$\bf R$}}
\newcommand{\matC}{\mbox{$\bf C$}}
\newcommand{\bnab}{\boldsymbol{\nabla}}
\newcommand{\bnabg}{\boldsymbol{\nabla_g}}
\newcommand{\galsim}{\texttt{GALSIM}}
\newcommand{\ngmix}{\texttt{ngmix}}
\newcommand{\nnsim}{\texttt{nsim}}
\newcommand{\snr}{$S/N$}
\newcommand{\sn}{$S/N$}
\newcommand{\coadd}{{\rm coadd}}
\newcommand{\desreq}{$4\times 10^{-3}$}
\newcommand{\lsstreq}{$2\times 10^{-3}$}

\newcommand{\calexp}{\texttt{Exposure}}
\newcommand{\dm}{\texttt{LSST DM}}

\newcommand{\mcal}{\textsc{metacalibration}}
\newcommand{\mdet}{\textsc{metadetection}}
\newcommand{\Mcalshort}{\textsc{metacal}}
\newcommand{\Mcal}{\textsc{Metacalibration}}
\newcommand{\Mdet}{\textsc{Metadetection}}
\newcommand{\vest}{\mbox{\boldmath $e$}}
\newcommand{\est}{e}
\newcommand{\mcalR}{\mbox{\boldmath $R$}}
\newcommand{\mcalRS}{\mbox{\boldmath $R_S$}}
\newcommand{\gest}{\mbox{\boldmath $\hat \gamma$}}
\newcommand{\vecgam}{\mbox{\boldmath $\gamma$}}

\newcommand{\sx}{\textsc{Source Extractor}}

\newcommand{\bfd}{\textsc{BFD}}

\newcommand{\vonkarman}{{von K\'arm\'an}~}


%\setuphead[section][before={\testpage[2]}]

%mnras
%\title[\Mdet]{\Mdet: Mitigating Shear-dependent Object Detection Biases with \Mcal}

%\author[Sheldon et~al.]{Erin Sheldon$^1$, Matthew R. Becker$^2$,
%Niall MacCrann$^{3,4}$, Michael Jarvis$^5$
%  \\$^1$Brookhaven National Laboratory, Bldg. 510, Upton, NY 11973, USA
%  \\$^2$High Energy Physics Division, Argonne National Laboratory, Lemont, IL 60439, USA
%  \\$^3$Center for Cosmology and Astro-Particle Physics, The Ohio State University, Columbus, OH 43210, USA
%  \\$^4$Department of Physics, The Ohio State University, Columbus, OH 43210, USA
%  \\$^5$Department of Physics and Astronomy, University of Pennsylvania, Philadelphia, PA 19104, USA
%}


% apj
\shorttitle{Metadetection for Rubin}
\shortauthors{Sheldon, Becker, Jarvis, Armstrong}

\begin{document}
% mnrad
% \date{Draft \today}

% mnras
%\maketitle


% apj
%\title{\Mdet: Mitigating Shear-dependent Object Detection Biases with \Mcal}
\title{Metadetection for the Vera C. Rubin Observatory}

\author{Erin S. Sheldon}
\affil{Brookhaven National Laboratory, Bldg 510, Upton, New York 11973, USA}
\author{Matthew R. Becker}
\affil{High Energy Physics Division, Argonne National Laboratory, Lemont, IL 60439, USA}
\author{Michael Jarvis}
\affil{Department of Physics and Astronomy, University of Pennsylvania, Philadelphia, PA 19104, USA}
\author{Robert Armstrong}
\affil{Lawrence Livermore National Laboratory, Livermore, CA 94551, USA}


\begin{abstract}

    \Mcal\ for LSST

\end{abstract}

% \newpage
% \tableofcontents

\section{Introduction} \label{sec:intro}

\esstodo{}

\section{Simulation Features} \label{sec:sim}

The basic simulation was similar to that created for the \mdet\ \citep{mdet20}
and by \citet{BeckerMdetCoadd} when testing the coadding algorithms for \mdet\ used
in this work. We added additional
features related to saturated stars which we will describe in the following
sections.  All images were rendered using the \galsim\ python package \esstodo{
cite galsim}.

We simulated what are known in the LSST data management system (\dm, version 0.2021.32, \esstodo{cite}
as calibrated exposure images.  This data is stored in a \calexp\ data
structure, which carries a calibrated, background subtracted image, along with
an estimated noise variance image plane, world coordinate system transformation
(WCS) and position dependent PSF model.  Problem areas associated with
saturation, cosmic rays, and bad columns are marked as separate bits in an
integer big mask image plane.

Other than background esimation errors (see \S \ref{sec:sim:bgerr}), we did not
test scenarios where the input data were mis-calibrated.  For example we did
not test the bias due to an incorrect PSF model, mis-estimated noise or bad
photometric calibration.  Our motivation was to test the performance of \mdet\
using well understood data.

For this work, we used the newly written simulation package
\texttt{descwl-shear-sims} version
0.4.2\footnote{\url{https://github.com/LSSTDESC/descwl-shear-sims}}.

\subsection{Image Filters and Noise} \label{sec:sim:noise}

We used the \descwl\ package \esstodo{cite} to determine the
noise for images in each filter.  In all simulation runs we used predicted
noise $n$ for the final 10 year coadd.  For individual simulated epochs we
re-scaled the noise appropriately, such that the noise in each epoch was $n *
\sqrt{N}$.  We used a Guassian random field to simulate the noise, which is a
good approximation at the expected noise levels \esstodo{cite}.

We did not add the expected amount of background to each image (but see \S
\ref{sec:sim:bgerr}).  After drawing all image features and adding
noise, we re-scaled the images to a common zero point of 30.

\subsection{Image World Coordinate System, Rotations and Dithers} \label{sec:sim:rotdith}

Each image was simulated as a tangent plane projection of the sky onto the
image frame with the LSST camera pixel scale of 0.2 arcseconds \esstodo{reference}.
The world coordinate system (WCS) transformation between sky and pixel
coordinates was represented as a \galsim\ \texttt{TanWCS} object.  Each
simulated WCS transformation had a random rotation applied, in order to mock up
the camera rotations used by LSST cam \esstodo{cite proper paper}.  The center of
each image was shifted, or ``dithered'', randomly in two dimensions relative to
the center of the desired coadded image.  We choose the dithers to be a
unrealistically small, within two pixels, to minimize portions of the image
that would not overlap the final coadd.  We created images with size just large enough
so that the rotated image, after dithers, would have no edge crossing the coadd
region, again to avoid waste:  coadding an image with an edge produces a
discontinuous PSF in the final coadd, so such images would be discarded.

\subsection{Point Spread Function} \label{sec:sim:psfs}

For our basic PSF model we used a Moffat profile \citep{Moffat1969} with
shape parameter $\beta=2.5$ and full width at half maximum (FWHM) of 0.8 arcseconds.

We also generated spatially variable PSF models using the methods described in
Appendix~A of \citet{SheldonMdet2020} based on work by \citet{heymans2012}.
\citet{heymans2012} used images with high stellar density to fit a \vonkarman\
model of atmospheric turbulence to the PSF variation. \citet{SheldonMdet2020}
used this model, with a modification to reduce power below 1'', to generate
realizations of spatially variable PSFs using Gaussian random fields. The PSF
model is a Moffat \citep{Moffat1969} profile with shape parameter $\beta=2.5$
and variable size and shape. In \citet{SheldonMdet2020} this approximate
variable PSF model was compared to detailed atmospheric and optics simulations.
It's parameters were set to generate the typical spatial PSF variance than one
expects for Rubin exposures. The median FWHM of the generated PSFs was 0.8
arcseconds.  We also ran simulations with larger than expected variations in
order to test the accuracy of the PSF coadd under extreme conditions.

\subsection{Stars} \label{sec:sim:stars}

We simulated stars using fluxes and densities sampled from the LSST DESC DC2
simulation \esstodo{cite}.  For each simulated field we sampled randomly, with
replacement, from the map of stellar density used to generate DC2, with a
maximum allowed density of 100 per square arcminute.  This density represents
the total number of stars drawn, not the number detected.  To determine each
stars multiband flux, we sampled stars from the DC2 star catalog.  We modeled
each star as a small Gaussian (FWHM $= 10^{-4}$ arcsec) convolved with the
point spread function.  We drew stars at random locations, even when galaxies
were drawn on a grid layout (see \S \ref{sec:sim:layouts}).  Stars were allowed
to saturate and have an associated bleed trail (see
\S \ref{sec:sim:satbleeds}).

\subsection{Image Saturation, Star Masking and Star Bleed Trails} \label{sec:sim:satbleeds}

The value in each pixel was artificially limited in order to simulate
saturation, and saturated pixels were marked with the appropriate flag an
integer bitmask image, and set the variance is set to infinity.  Non linear
detector response was not simulated.

Saturated stars were over-drawn with a simulated bleed trail image, taken from
a set of previously generated templates.  The bleed templates were identified
in images of bright stars created using the DC2 code.  For each saturated star
in our simulation, we found a close template match in the filter of interest
and drew the associated bleed image directly over the star image with a value
set to the saturation level. The bleed pixels were marked with the appropriate
flag in the bitmask.

We marked saturated stars in the bitmask image with a circular mask that
covered the star out to the radius where the profile reached the noise level.
Note in real data such a mask would need to be determined algorithmically.
This mask does not necessarily cover the bleed trail completely, although the
trail was interpolated (see \S \ref{sec:coadding}).  We find that these
unmasked trails do not cause a shear bias, which we attribute to the
camera rotations that randomize the direction of the trail on the sky.

Masks with sharp features can cause ringing in the FFTs used
by the \mdet\ algorithm.   Each star mask is like a circular ``tophat'',
which will have a sharp feature where it intersects an object in the image.  We
mitigated this effect using the apodization
procedure described in \citet{BeckerMdetCoadd}. We extended the star
mask by 16 pixels and forced the mask
to smoothly transition from zero in the interior of the circle
to unity at the expanded edge. The transition region was parameterized using the cumulative
integral of a triweight kernel. This kernel is a function of two parameters, $m$ and $h$,
and is defined for a point $x$ with quantity $y = (x-m)/h$ as
\begin{equation}
K(x, m, h) = \begin{cases}
0 & y < -3 \\
(-5y^7 / 69984 \\
+ 7y^5 / 2592 \\
- 35y^3 / 864 & -3 \le y \le 3 \\
+ 35y / 96 \\
+ 1 / 2) \\
1 & y > 3
\end{cases}
\end{equation}
The kernel goes from zero to unity over a span of $6h$, centered on $m$.
The general logic is to set $h$ large enough that the variation across the edge is slower
than the variation given by the PSF profile, but not so large that area in the image is
wasted. We set $h$ to 1.5 pixels and set $m$ to the radius of the star mask hole.

\subsection{Cosmic Rays \& Bad Columns} \label{sec:sim:cosmics_badcols}

We followed \citet{BeckerMdetCoadd} in generating bad column and cosmic ray artifacts.
For cosmic rays, we selected a random location on the image, a random angle, and a random
length between 10 and 30 pixels. We then flagged pixels along this line as having been hit
by a cosmic ray, making sure that pixels that touch only along corners have the pixels
directly adjacent to them flagged as well. We set a cosmic ray bit in the bitmask for
interpolation later and set the image value to \texttt{NaN} to ensure that no flagged
pixels are inadvertently used in the final shear estimates.

We generated bad column masks using a slightly modified Monte Carlo generator
from \citet{BeckerMdetCoadd}. Each bad column was a single pixel wide,
positioned randomly on the image. We also added gaps at random to the bad
columns to simulate bad columns which do not span the full CCD.  We generated
a single bad column for each image.

The LSST lensing analysis will be carried out on coadd images of hundreds of
exposures, with artifacts interpolated on the original data before being warped
and added.  The aggregate number of artifacts will be large, but the impact of
each artifact will be relatively small.  It was not computationally feasible to
simulate such a large number of epochs in order to test the effect of artifacts
in a realistic way.  Rather we simulated a smaller number of epochs per
band, typically
1 but up to 10, with the noise scaled so that the final coadd noise matched
LSST 10 year data.  Thus, relative to expected LSST data the impact of each
artifact on the coadd was large but the aggregate number of artifacts was
small.

\subsection{Galaxies} \label{sec:sim:galaxies}

We used the \descwl\ package to generate galaxy models \esstodo{cite}.  These
elliptical, color models have bulge, disk and AGN components. We performed the
drawing of these models in our code in order to enable the use of our on PSF
models (see \S \ref{sec:sim:psfs}, and to allow for more efficient drawing.

We also performed simulation runs with one component, round exponential
galaxies with fixed flux and size.  These models are useful for shear recovery
tests that do not require a realistic galaxy population, but benefit from using
low shape noise shear tracers.  These models were most often used as moderately
fast, full shear recovery tests, to further test code changes
that have already passed the fast unit tests.

\subsection{Layouts} \label{sec:sim:layouts}

We ran tests with both random and gridded galaxy layouts.  The random layout
was used with the realistic galaxy population, and the density of objects
reflected the expected density of galaxies as defined in the \descwl\ package.

The grid was used with the simple, round exponential galaxies to facilitate
moderately fast shear recovery tests.  The grid is square, with spacing
designed to avoid overlap between adjacent galaxies, and thus avoid blending
effects.

See \S \ref{sec:sim:galaxies} for descriptions of each galaxy model type.

\subsection{Image Background} \label{sec:sim:bgerr}

We add a negative constant to the images to approximate errors in the
background determination.  The motivation is to test if errors for individual
epochs can be corrected in the final coadd image by running a second background
determination \esstodo{reference a section where the result is mentioned}.

\subsection{Shear Patterns} \label{sec:sim:shears}

We implemented two different types of shear pattern.  In one we used a single
shear for all images, with constant magnitude and orientation.  The second type
was a constant magnitude shear, but with random orientation for each image.
These two scenarios result in equivalent shear recovery bias when objects are
not divided into cells on the sky (see \S \ref{sec:sim:cells}) but, as we will
see in \S \ref{sec:results:cells}, a small additional selection bias is
introduced for random shears when when trimming to cells.

\subsection{Overlapping Coadd Cells} \label{sec:sim:cells}

Coadds can be used for shear measurement \esstodo{cite bob's paper}, but we
require that the coadded images have a continuous PSF in order to faciliate
accurate PSF modeling.  Images that have an edge in the coadd region must be
rejected.  Smaller coadds result in fewer images being rejected, but very small
coadds would complicate object identification deblending.  For LSST, we plan to
use relatively small (250x250 pixels) overlapping (50 pixels) coadded regions
for shear measurement, which we call ``cells'' \esstodo{cite}.

We ran simulations with and without cells in order control for issues specific
to the cell processing and trimming of objects to non overlapping regions.  We
adopted the cell definitions outlined above: 250x250 pixel cells with 50 pixel
overlaps. The object list was trimmed to the non-overlapping region in post
processing.

\subsection{Noise Images} \label{sec:sim:noiseimages}

The \mcal\ procedure involves deconvolution by the PSF, shearing of the image,
and reconvolution by a round kernel.  This process alters the noise and
produces a spurious shear response.  We can cancel this bias by adding a noise
image, with properties that statistically match the real background noise,
processed in a similar manner but with orthogonal shear.  We stored this
noise image in a copy of the image \calexp\ structure, but replacing the
real image data with the noise image.

\begin{figure}
    \includegraphics[width=\columnwidth]{example-image.jpg}
    \caption{
        Example simulated image. \esstodo{caption}
    }
\end{figure}
\begin{figure}
    \includegraphics[width=\columnwidth]{example-masked-image.pdf}
    \caption{
        Example masked images. \esstodo{caption}
    }
\end{figure}



\section{Image and PSF Coaddition} \label{sec:coadding}

For coaddition, we used the package \texttt{descwl\_coadd} version
0.3.0\footnote{\url{https://github.com/LSSTDESC/descwl_coadd}}.  This code uses
\dm\ algorithms for warping images onto the coadd pixel grid, in particular the
\texttt{AccumulatorMeanStack} from \texttt{lsst.meas.algorithms} sub package.
We used an inverse variance weighting, based on the noise in the image.

Before warping, we interpolated artifacts such as cosmic rays, bad columns, and
saturated pixels.  The interpolation and warping modifies the noise properties
of the image.  Thus, for accurate \mcal\ noise corrections (see \S
\ref{sec:sim:noiseimages}) we must also run the noise image through the same
procedures.  Rather than use the \dm\ codes, we performed all interpolation of
artifacts and saturated regions using the \texttt{CloughTocher2DInterpolator}
from the scipy software
package\footnote{\url{https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.CloughTocher2DInterpolator.html}}.
We used this interpolation because the \dm\ cosmic ray interpolation available
at the time of writing is intertwined with the detection of cosmic rays, so
cannot be run on the noise image.

Using the same code, we also created PSF coadded images.  For each input image,
we generated an image of the PSF at the location of the coadd center, including
any sub-pixel offsets between the pixel grids, so the PSF images where
generally not centered.  We then warped on these images using the same weights
as the image data.  This off-centering and warping is important so that the PSF
includes the same small amount of smearing present in the image interpolation.
Not including this offset results in percent level multiplicative shear biases
\esstodo{cite bob's paper}.  Note \dm\ provides a PSF coadding code, but at the
time of writing it did not perform sub-pixel offsets, so was unsuitable for
our purposes.

The resulting coadd and PSF coadd data were stored in a new \calexp\ data
structure for use in \mdet.

\section{Metadetection} \label{sec:mdet}

For shear inference we used the \mdet\ method presented in \cite{mdet20}.
\Mdet\ is an extension of the \mcal\ method
\citep{HuffMcal2017,SheldonMcal2017} to include the object identification
stage. We call this ``detection'', meaning specifically object identification
rather than detection of pixels with significant signal.  \Mdet\ mitigates
biases due to the shear-dependent nature of the detection processing in finite
resolution images, which are expected to be a few percent for LSST
\citep{mdet20}.

Briefly, with \mdet\ we assume that the true applied, two-component shear
$\boldsymbol{\gamma}$ is small, so that a measured ellipticity $\boldsymbol{e}$
of a galaxy is linear in the shear:
\begin{eqnarray} \label{eq:response}
\boldsymbol{e} & \approx & \left.\boldsymbol{e}\right|_{\gamma=0} +
                           \left.\frac{\partial \boldsymbol{e}}{\partial\boldsymbol\gamma}\right|_{\gamma=0} \boldsymbol\gamma +
                           O(\boldsymbol\gamma^2)\nonumber\\
               & \equiv  & \left.\boldsymbol{e}\right|_{\gamma=0} +
                           \boldsymbol{R} \boldsymbol\gamma +
                           O(\boldsymbol\gamma^2)
\end{eqnarray}
Here, the matrix $\boldsymbol{R}$ represents the linear response of the
measurement to an applied shear. It can be written component wise as
$R_{ij}=\partial e_i /\partial \gamma_j$, with $i$ and
$j$ taking all combinations of the two shear components.  For ellipticity
measurements we use weighted moments (see \S \ref{sec:mdet:meas}).

We use a finite difference to estimate $\boldsymbol{R}$.  The image is
deconvolved by the PSF, sheared, and reconvolved with a round kernel.  This
process is repeated for a small positive and negative shear, and a finite
difference response term is formed
\begin{equation}
R_{ij} \approx \frac{e_i^{+} - e_i^{-}}{\Delta\gamma_j}\ .
\end{equation}
where $e_i^{+}$ is measured on the positively sheared image and $e_i^{-}$ is
measured on the negatively sheared image.

As mentioned in \S \ref{sec:sim:noiseimages}, the deconvolve, shear, reconvolve
process produces a spurious shear response that we correct by adding a noise
image run through the same process but with orthogonal shear.

The responses too noisy to be applied to individual ellipticity measurements.
We instead average the shapes and responses in equation \ref{eq:response} to
recover a mean shear \vecg
\begin{eqnarray} \label{eq:shearmeas}
    \left< \boldsymbol{R} \right> &=& \left< \frac{\partial \boldsymbol{e} }{\partial \boldsymbol{\gamma} } \biggr\rvert_{\gamma=0} \right>, \nonumber \\
    \langle R_{ij}\rangle &=& \left< \frac{e_i^{+} - e_i^{-}}{\Delta\gamma_j} \right>, \nonumber \\
    \langle \vecg \rangle & \approx & \langle \boldsymbol{R}\rangle^{-1}\langle\boldsymbol{e}\rangle.
\end{eqnarray}

However, this process is incomplete:  the detection phase also depends on
shear.  We can incorporate detection by running object detection on the image
as well as the sheared images independently and producing the averages from
separate catalogs.  Moving the derivative outside of the average, we find
\begin{eqnarray} \label{eq:fullR}
    \left< \boldsymbol{R} \right> &=& \frac{\partial \left< \boldsymbol{e} \right> }{\partial \boldsymbol{\gamma} } \biggr\rvert_{\gamma=0},  \nonumber \\
    \langle R_{ij}\rangle &=& \frac{\langle e_i^{+}\rangle - \langle e_i^{-}\rangle}{\Delta\gamma_j} \nonumber \\
\end{eqnarray}
where now the averages for $e_i^{+/-}$ are for object catalogs found on the
respective ${+/-}$ sheared image.

For \mdet, we used the package \texttt{metadetect} version
0.8.2\footnote{\url{https://github.com/esheldon/mdetadetect}}.  In the following subsections
we will describe parts of this process in more detail.

\subsection{Creation of Sheared Images} \label{sec:mdet:sheared}

For this work we used \dm\ data structures to represent image data (see \S
\ref{sec:sim}).  We adapted the \mcal\ implementation for creating sheared
images from the \texttt{ngmix}
package\footnote{\url{https://github.com/esheldon/ngmix}} to use these data
structures.  The new code is part of the \texttt{metadetect} software package.


\subsection{Detection and Deblending} \label{sec:mdet:detect}

We used the \dm\ algorithm for detection \esstodo{cite Jims paper}.  We ran with
the default settings at the time of writing, which retains sources with a
$S/N \gtrsim 5$ calculated from a PSF template flux measurement.

Deblending was performed during the object detection phase as part of the
process of finding sub-peaks, but we did not use the deblender to remove the
light of neighboring objects when measuring object properties (see \S
\ref{sec:mdet:meas}).  We found that using the models to remove neighbor light
resulted in shear biases of order ten percent.

We did limited testing with the Scarlet \esstodo{cite} deblender, which has
recently received support in the \dm\ software stack. Scarlet performed better
in the tests we performed, showing a bias of $< 1$\%, but due to the high
computational cost of the deblender, we did not gather enough statistics to
perform more precise tests.

As we will show in \S \ref{sec:results}, measuring shapes without deblending
the light of neighbors caused no detectable bias.  However, deblending will
presumably improve the performance of other critical algorithms such as
redshift determination.  We will explore deblending more in future work.

\subsection{Object Measurement} \label{sec:mdet:meas}

We used version v2.1.0 of the \ngmix\ package to measure weighted moments for
each detected object. The weight function was a fixed, circular, Gaussian $G(x,
y)$ with FWHM=1.2 arcseconds.  We recorded the flux,
S/N, second moments, and ellipticity derived from the second moments:
\begin{eqnarray} \label{eq:moments}
    F &=& \sum G(x, y) I(x, y) \nonumber \\
    \sigma^2(F) &=& \sum \sigma^2(I(x, y)) \nonumber \\
    T &=& \sum G(x, y) I(x, y) ~ (x^2 + y^2) \nonumber \\
    M_1 &=& \sum G(x, y) I(x, y) ~ (x^2 - y^2) \\
    M_2 &=& \sum G(x, y) I(x, y) ~ 2 x y \nonumber \\
    e_1 &=& M_1 / T \nonumber \\
    e_2 &=& M_2 / T \nonumber \\
    S/N &=& F / \sigma(F) \nonumber
\end{eqnarray}
where $I(x, y)$ is the intensity of the image, and $\sigma^2(I(x, y))$ is the
noise variance. The sums run over all pixels in a 48x48 postage stamp image
extracted around the object of interest.  The $x$ and $y$ coordinates are
relative to the center found during detection.  Note in practice we weight each
pixel in the sum by the inverse noise variance. However, the noise variance is
nearly constant across the coadd so this is only relevant for masked, zero
weight pixels.  Note $T$ is an estimate of the observed square size of
the, not the pre-PSF size.

We also record the moments of the coadded PSF for use in object selection (see
\S \ref{sec:results:full}).


\section{Running the Simulation and Metadetection} \label{sec:running}

We used the ``wrapper'' package \texttt{mdet-lsst-sim} version
0.3.4\footnote{\url{https://github.com/esheldon/mdet-lsst-sim}} to run the
simulation, coaddition and \mdet, and to organize, submit and collate large
runs on computing clusters.

In all cases we used a constant shear, with possible random orientations for
each simulated scene (see \S \ref{sec:sim:shears}).  We simulated each scene
with equal but opposite shears in order to implement the noise canceling method
of \citep{pujol2019}.  For randomized shear directions, the shape measurements
from different scenes where placed in a common reference frame before averaging
to get a mean shear.

We estimated the uncertainty in the averaged shear measurements using a
jackknife technique, with chunks defined as a few tens to hundreds of scenes.

\section{Results} \label{sec:results}

In this section we present the results for various simulation and analysis
configurations.

We consider our ``base'' simulation to be one with fixed size, high S/N, round
galaxies on a grid layout, which provides the highest signal-to-noise ratio for
the shear recovery. From the results in \citet{mdet20}, we expect a small bias
in this configuration due to higher order shear effects (see \S
\ref{sec:results:base}).

We performed shear recovery with each additional feature separately in order to
isolate the cause of potential biases.  We found a bias only in the case of
extreme spatial PSF variation with few simulated epochs (see \S
\ref{sec:results:psfvar}).  We present results with all simulated features in
\S \ref{sec:results:cells}.

To characterize the bias, we assume a simple linear model \citep[see,
e.g.,][]{heymans2006} for estimating a bias in the recovered shear
\begin{equation} \label{eq:m}
\vecg = \vecc + (1 + \vecm) \vecgam
\end{equation}
where \vecg\ is the inferred shear, measured using equation \ref{eq:shearmeas},
\vecgam\ is the true shear, \vecc\ is the additive bias, and \vecm\ is the
multiplicative bias. We found \vecc\ was consistent with zero in all tests, so
in what follows we only report \vecm.

\subsection{Baseline Results for Fixed Galaxies on a Grid} \label{sec:results:base}

In order to establish a baseline for the bias due to higher order shear
effects, we ran a simulation with fixed, round exponential, S/N $= 10,000$,
half light radius 0.5 arcsecond galaxies placed in the grid layout (see
sections \ref{sec:sim:galaxies} and \ref{sec:sim:layouts}) with image dithers
and rotations.  In order to make the test as efficient as possible, we used
only the $i$ band with a single image ``epoch'', but with approximately the
full expected LSST 10 year depth in the combined $r, i, z$ bands.  We used a
fixed Moffat PSF\citep{Moffat1969} with FWHM=0.8.  We expect a bias $m$ of a
few parts in ten thousand for this sim \citep{SheldonMcal2017}.  We found a
bias of $4.2\times 10^{-4} < m < 4.3\times 10^{-4}$ (99.7\% confidence),
consistent with our expectations.

We reran this simulation after all major code updates as a kind of extended
unit test to look for bugs and regressions.

\subsection{PSF Variation} \label{sec:results:psfvar}

\mdet\ requires artificially sheared versions of each coadd image (see \S
\ref{sec:mdet}).  This process involves deconvolving the image by the PSF (see
\S \ref{sec:mdet}).  This would require a spatially dependent convolution
kernel when the PSF has spatial variations.  However, due to the camera
rotations, and large number of images used to make the coadd, we expect most of
this PSF variation to be averaged down.  Thus the single coadded PSF that we
generate at the coadd center (see \S \ref{sec:sim:psfs}) may be sufficient.

We ran the same grid simulation from \S \ref{sec:results:base} with the
spatially varying PSF presented in \S \ref{sec:sim:psfs}. We used the $r, i, z$
bands but with a single image epoch per band, with rotations and dithers. We
did not see any increase in the bias.   We interpret this result to indicate
that the PSF variation is small enough that our single coadded PSF is
sufficient, even with a single image per band.

We also ran with the same simulation configuration, but with ten times the
expected PSF variation. In this case, for a single, full depth image per band,
we found a small increase in the bias $m \sim 0.0016$.  However, after
increasing the number of simulated epochs per band to ten, we found this extra
bias was removed.  We interpret this to mean that more epochs are required to
cancel out very large PSFs.  LSST will take hundreds of images in each band
(\esstodo{cite}), so we do no expect PSF variation to be a significant source
of bias.

For the remaining tests in this paper we use the spatially variable PSF with
expected variation level.

\subsection{Results with Additional Simulation Features} \label{sec:results:more}

We ran the simulation with realistic galaxies, random layout, and image
artifacts, and background subtraction errors, as listed in \S \ref{sec:sim}.
For the realistic galaxy configuration, we adopted a basic set of cuts
\begin{eqnarray}
    \mathrm{S/N} & > & 12.5 \\
    T/T_{PSF} & > & 1.2
\end{eqnarray}
where $T$ is the Gaussian weighted square size of the observed, PSF convolved
image, as defined in equation \ref{eq:moments}, and $T_{PSF}$ is the
corresponding value for the PSF.  The lower \snr\ cut is motivated by
the noise study in \S \ref{sec:results:sdensnoise}, and the lower cut
on $T/T_{PSF}$ represents a typical attempt to remove stars from the sample.

We turned on each feature separately in order to isolate possible biases.  In
no case did we find additional bias in the shear recovery beyond that expected
from higher order shear effects (see \S \ref{sec:results:base}).

\subsubsection{Results with Varied Selections on Object Properties} \label{sec:results:select}

We varied the selections on object size ratio $T/T_{PSF}$ and \snr\ and
repeated the shear recovery analysis.  The results are shown in figure
\ref{fig:trends}, for both constant and spatially varying PSFs (see \S
\ref{sec:sim:psfs}).  We did not detect any additional bias.  Note that
stricter cuts on \snr\ resulted in lower noise for this plot due to the noise
cancellation procedure which works better for bright objects.  We will explore
the shear sensitivity without noise cancellation in \S
\ref{sec:results:sdensnoise}.

\begin{figure}
	\includegraphics[width=\columnwidth]{{trends}.pdf}
	\caption{\esstodo{caption}} \label{fig:trends}
\end{figure}

\subsection{Results with Overlapping Coadd Cells} \label{sec:results:cells}

We ran a modification of the base simulation as described in \S
\ref{sec:results:base} with a randomized position layout and overlapping cells
as described in \S \ref{sec:sim:cells}.  Because the cells overlap, the catalog
created for each coadd must be trimmed to a unique region.  Shear changes the
locations of objects, so this trimming introduces a shear dependent selection
effect.

In the case where the true simulated shear aligns with the artificially applied
shear used to create the \mcal\ images, we found that \mdet\ provided
an accurate calibration.  However, when using randomized shear
orientations (see \S \ref{sec:sim:shears}), we found the multiplicative bias
$m$ was reduced below the expected bias due to higher order shear effects by
about $-0.0004$.  Our inerpretation is that the artificial shearing slightly
over-predicts the selection effect when it is not perfectly aligned with the
true shear.  This bias is smaller than LSST requirements $|m| \lesssim 0.001$.
However, we speculate that using artificial shears with random orientations
could mitigate this effect.  We may explore this more in a future work.

\subsection{Results with Stars and Bleed Trails} \label{sec:results:full}

\subsubsection{Dependence of Shear Bias on Stellar Density Cut} \label{sec:results:sdens}

Our ``full'' simulation configuration included stars and bleed trails as
described in \S \ref{sec:sim:stars} and \ref{sec:sim:satbleeds}, in addition to
the features tested in the previous sections.  In figure \ref{fig:stardens} we
show the multiplicative bias as a function of maximum stellar density and
various cuts on the measured signal to noise ratio in addition to a cut on size
ratio $T/T_{PSF} > 1.2$. \esstodo{describe results and also show with weights}

\begin{figure}
    % \includegraphics[width=\columnwidth]{{run-riz-drcbWsBPv0.1-cells-s2n-imfrac0.10-mfrac0.02}.pdf}
	\includegraphics[width=\columnwidth]{{stardens-bias}.pdf}
	\caption{\esstodo{caption}} \label{fig:stardens}
\end{figure}



\subsubsection{Dependence of Shear Sensitivity on Object Selections}
\label{sec:results:sdensnoise}

\esstodo{add result with weights}

We explored what set of cuts on stellar density and \snr\ result in the lowest
noise in the recovered shear.  For our measure of uncertainty we used only one
of the paired images used for noise cancellation.  This is because the noise
cancellation is more effective for higher \snr\ objects, resulting in smaller
uncertainties for higher minimum \snr\ cuts, which is not true for real data.

In figure \ref{fig:stardenserror} we show the uncertainty in the recovered
shear as a function of maximum allowed stellar density and \snr\ cut, relative
to the cuts that provide the lowest noise.  We find the lowest uncertainty for
the case of maximum stellar density less than 60 per square arcminute and a
minimum \snr\ of 12.5.  The dependence is fairly flat for \snr\ cuts above 12.5
and stellar density above 40 per square arcminute.  We find that including
higher stellar density areas reduces the noise, but with limited benefit beyond
a density of about 40 stars per square arcminute.

\begin{figure}
    \includegraphics[width=\columnwidth]{{stardens-nocancel-error}.pdf}
	\caption{\esstodo{caption}} \label{fig:stardenserror}
\end{figure}


Although we find no significant increase in shear bias when including images
with higher stellar density, it may be beneficial to exclude them for other reasons,
such as to reduce the impact of interstellar extinction or other sources of
error that correlate with stellar density.  Such cuts could be tuned
to provide a beneficial trade off between accuracy and shear sensitivity.

We find that including detections with \snr\ as low 10 does not reduce the
shear uncertainty compared to cutting at 12.5 or 15.  It may seem surprising
that including more resulted in a noisier measurement.  This can
occur with \mcal\ because the shear estimator involves dividing by the mean
response, which is typically smaller and noisier for lower \snr\ objects.
However, we have two notes on this.  First, we did not use any explicit
weighting of the ellipticities when calculating the mean shear.   It may be
that a smooth weight that is a function of \snr, $T$, and other relevant
parameters will provide a better sensitivity \esstodo{cite Y3 paper weighting}.
Second, these results will vary significantly with the measurement type, for
example the specific weight function used or the model that is fitted,
each of which will provide a different estimate of the \snr.

\subsection{Shear Sensitivity and Effective Density} \label{sec:results:effdens}

\esstodo{add with weights}

The uncertainties presented thus far are artificially reduced due to the noise
canceling effect (see \S \ref{sec:running}).  In order to estimate the noise
we expect for LSST, we used measurements from just one of the two paired images.

For the results shown in \S \ref{sec:results:full}, we simulated approximately
22,000 square degrees of images, with about 6\% of that area masked due to
bright stars and defects.  We converted the measured variance to an
effective density using a simple formula \esstodo{citation for equation?}
\begin{equation} \label{eq:neff}
    n_{\mathrm{eff}} = \frac{\sigma^2_{SN}}{R^2 \mathrm{A} \sigma^2_{\gamma}}.
\end{equation}
In equation \ref{eq:neff}, $R \sim 0.264$ is the scalar response from averaging
the diagonal components of the response matrix, $\sigma_{SN} \sim 0.120$ is the
shape noise for our catalog after cuts, $\sigma_{\gamma} \sim 8.05 \times
10^{-6}$ is the $1-\sigma$ uncertainty in the recovered shear without noise cancellation,
and $A \sim 22,000 \times 0.94 = 20680$ is the effective simulated area after
masking.  We find $n_\mathrm{eff} \sim 43$
per square arcminute for basic cuts (see \S \ref{sec:results:more}), and a cut
on stellar density of 60 per square arcminute, and no explicit weighting
scheme.  The effective density will vary with the choice of ellipticity
estimate, and may be improved with optimized weights.


\section{Summary} \label{sec:summary}

\esstodo{}

\section*{Acknowledgments}

ES is supported by DOE grant DE-AC02-98CH10886, and MRB is supported by DOE
grant DE-AC02-06CH11357. RA is supported by the US Department of Energy Cosmic
Frontier program, grant DE-SC0010118.  \esstodo{Mike's funding}

We thank Javier Sanchez for providing the star and stellar density map for DC2,
and Jim Chiang for providing example images containing simulated stars
with bleed trails.

We thank the excellent computing staffs of the RHIC Atlas Computing Facility at
Brookhaven National Laboratory and the Scientific Computing Services team at
the SLAC National Accelerator Laboratory for their support.

\esstodo{}


%\bibliographystyle{mnras}
%\bibliography{references}
%\bibliography{apj-jour,references}
%\bibliographystyle{apj}
\bibliographystyle{aasjournal}
\bibliography{references}

\end{document}
